{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Open the file correctly\n",
    "cloud = xr.open_dataset(cp, engine=\"netcdf4\", decode_times=False, mask_and_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ddaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from pyproj import Transformer\n",
    "\n",
    "cp = \"\"\n",
    "var = \"\"\n",
    "\n",
    "\n",
    "cloud = xr.open_dataset(cp, engine=\"netcdf4\", decode_times=False, mask_and_scale=True)\n",
    "\n",
    "lat = cloud[\"Latitude\"].data\n",
    "lon = cloud[\"Longitude\"].data\n",
    "dat = cloud[var].data\n",
    "\n",
    "# Step 1: filter valid data points\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    qa = cloud[\"Quality_Assurance_5km\"].astype(\"uint16\")\n",
    "\n",
    "cot_use = (qa[:, :, 1] >> 0) & 1\n",
    "cot_mask = (cot_use == 1)\n",
    "\n",
    "if cot_mask.sum().item() == 0:\n",
    "    cloud.close()\n",
    "    continue\n",
    "\n",
    "mask = np.isfinite(lat) & np.isfinite(lon) & np.isfinite(dat) & cot_mask\n",
    "lat = lat[mask]\n",
    "lon = lon[mask]\n",
    "dat = dat[mask]\n",
    "\n",
    "# Step 2: filter data points inside JX province\n",
    "xs, ys = transformer.transform(lon, lat)\n",
    "\n",
    "pts = gpd.GeoSeries(gpd.points_from_xy(xs, ys), crs=\"EPSG:4527\")\n",
    "inside = pts.within(jx_proj).values\n",
    "if inside.sum() == 0:\n",
    "    cloud.close()\n",
    "    continue\n",
    "\n",
    "xs = xs[inside]\n",
    "ys = ys[inside]\n",
    "dat = dat[inside]\n",
    "\n",
    "# Step 3: match with grids\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395492b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113.57276909724303, 24.488938802096126, 118.4821180557606, 30.079843918040275)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Anora Wu\n",
    "# Date: Jan 7th 2026\n",
    "# Construct a panel data, with each day between 2020-2025 being the time variable and each grid being the identity. \n",
    "# Each identity has a geometry and a id. \n",
    "# Fill in the cloud seeding operation day and location into the time slots and the grid \n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from shapely.geometry import box\n",
    "from pyproj import Transformer\n",
    "\n",
    "\n",
    "# Change to your rawdata directory\n",
    "os.chdir('/Users/anora/Team MG Dropbox/Wanru Wu/Cloudseeding_Anora')\n",
    "\n",
    "### CONSTRUCT GRID ###\n",
    "\n",
    "# Load and project JX polygon to EPSG:32650 \n",
    "jx_poly = gpd.read_file('jiangxi/jiangxi_shape.shp').geometry.iloc[0]\n",
    "jx_poly.bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# PPS Python ftps script\n",
    "# Usage:  python script.py   (requires Python 3)\n",
    "#\n",
    "\n",
    "import os, sys, hashlib\n",
    "from ftplib import FTP_TLS\n",
    "import urllib\n",
    "import urllib.request\n",
    "\n",
    "downloadCount=0\n",
    "skipCount=0\n",
    "ftpConnection=None\n",
    "forceHttps=False\n",
    "userid='wanru@uchicago.edu'\n",
    "\n",
    "def usage():\n",
    "  print ('Usage:  python script.py [https]  (requires Python 3)')\n",
    "  print ('Connects to the PPS ftps server and pulls files generated during order processing.')\n",
    "  print ('Confirms download with a SHA checksum calculation.')\n",
    "  print ('Will use https requests if connection to ftps server fails.')\n",
    "  print ('Argument:  https - force https connection')\n",
    "\n",
    "def hashfile(filename, blocksize=65536):\n",
    "  hasher = hashlib.sha1()\n",
    "  with open(filename, 'rb') as localfile:\n",
    "    buf = localfile.read(blocksize)\n",
    "    while len(buf) > 0:\n",
    "      hasher.update(buf)\n",
    "      buf = localfile.read(blocksize)\n",
    "  return hasher.hexdigest()\n",
    "\n",
    "def calcCksum(filename,cksum=None):\n",
    "  if (cksum):\n",
    "    sha = hashfile(filename)\n",
    "    print (' cksum Pass' if cksum==sha else ' cksum FAIL')\n",
    "  else:\n",
    "    print ('.')\n",
    "\n",
    "def get(filepath,cksum=None):\n",
    "  if (ftpConnection):\n",
    "    getFtpFile(filepath,cksum)\n",
    "  else:\n",
    "    getHttpsFile(filepath,cksum)\n",
    "\n",
    "def getFtpFile(filepath,cksum=None):\n",
    "  global ftpConnection,downloadCount,skipCount\n",
    "  path,filename=os.path.split(filepath)\n",
    "  ftpConnection.cwd(path)\n",
    "  download=True\n",
    "  ftpSize=ftpConnection.size (filename)\n",
    "  # determine if file exists in local directory\n",
    "  if (os.path.exists(filename)):\n",
    "    # check size and cksum\n",
    "    if (cksum):\n",
    "      sha = hashfile(filename)\n",
    "      download=(cksum != sha)\n",
    "    else:\n",
    "      filesize=os.path.getsize(filename)\n",
    "      download=(ftpSize!=filesize)\n",
    "\n",
    "  if (download):\n",
    "    # if not exists or file checks do not match, get file.\n",
    "    downloadCount+=1\n",
    "    sys.stdout.write( str(downloadCount)+') Downloading '+filename+'   '+str(ftpSize)+' bytes')\n",
    "    sys.stdout.flush()\n",
    "    with open(filename, 'wb') as localfile:\n",
    "      ftpConnection.retrbinary('RETR ' + filename, localfile.write, 1024)\n",
    "    calcCksum(filename,cksum)\n",
    "  else:\n",
    "    print ('Already downloaded '+filename)\n",
    "    skipCount+=1\n",
    "\n",
    "def getHttpsFile(filepath,cksum=None):\n",
    "  global downloadCount\n",
    "  path,filename=os.path.split(filepath)\n",
    "  with urllib.request.urlopen('https://arthurhouhttps.pps.eosdis.nasa.gov'+filepath) as response, open(filename, 'wb') as localfile:\n",
    "    downloadCount+=1\n",
    "    sys.stdout.write(str(downloadCount)+') Downloading '+filename)\n",
    "    sys.stdout.flush()\n",
    "    localfile.write(response.read())\n",
    "    localfile.close()\n",
    "    calcCksum(filename,cksum)\n",
    "\n",
    "def getPpsFiles():\n",
    "  global ftpConnection,forceHttps\n",
    "  print ('Connecting to PPS')\n",
    "  if forceHttps==False:\n",
    "    try:\n",
    "      ftpConnection = FTP_TLS('arthurhou.pps.eosdis.nasa.gov')\n",
    "      print (ftpConnection.getwelcome())\n",
    "      ftpConnection.login(userid,userid)\n",
    "      ftpConnection.sendcmd('TYPE i')\n",
    "      print ('Connected.  Getting files...')\n",
    "    except Exception as e:\n",
    "      print ('Failed to connect to the PPS ftps server due to ' + str(e))\n",
    "      print ('Trying https')\n",
    "      ftpConnection=None\n",
    "\n",
    "  if (ftpConnection==None):\n",
    "    password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    password_mgr.add_password(None,'https://arthurhouhttps.pps.eosdis.nasa.gov',userid,userid)\n",
    "    handler = urllib.request.HTTPBasicAuthHandler(password_mgr)\n",
    "    opener = urllib.request.build_opener(handler)\n",
    "    urllib.request.install_opener(opener)\n",
    "\n",
    "  # The following is the list of PPS files to transfer:\n",
    "  get('/gpmallversions/V07/2020/01/01/radar/2B.GPM.DPRGMI.CORRA2022.20200101-S095020-E112254.033194.V07A.HDF5','8d22ca9ef7262bcd784f34ea6d68b0a6d5b2d4c4')\n",
    "  get('/gpmallversions/V07/2020/01/02/radar/2B.GPM.DPRGMI.CORRA2022.20200102-S194705-E211938.033216.V07A.HDF5','5f642f6616cea4dc6bfc7fa34576a88d9863c587')\n",
    "  get('/gpmallversions/V07/2020/01/03/radar/2B.GPM.DPRGMI.CORRA2022.20200103-S094017-E111251.033225.V07A.HDF5','e9b7a0710f3c8190218328af62659773f7ec7760')\n",
    "  get('/gpmallversions/V07/2020/01/03/radar/2B.GPM.DPRGMI.CORRA2022.20200103-S185546-E202819.033231.V07A.HDF5','0637421e16e362c4d74872dc27312a6041ae6d14')\n",
    "  get('/gpmallversions/V07/2020/01/05/radar/2B.GPM.DPRGMI.CORRA2022.20200105-S184542-E201815.033262.V07A.HDF5','273b2d334eadb4c781c72c6c626226d4ef37678a')\n",
    "  get('/gpmallversions/V07/2020/01/06/radar/2B.GPM.DPRGMI.CORRA2022.20200106-S083854-E101127.033271.V07A.HDF5','4ea10f1809c96febdec7b543e9fcc88cf6875c1b')\n",
    "  get('/gpmallversions/V07/2020/01/06/radar/2B.GPM.DPRGMI.CORRA2022.20200106-S175422-E192655.033277.V07A.HDF5','f330c98b92c64ae9eb293d2308734e8230db5f10')\n",
    "  get('/gpmallversions/V07/2020/01/08/radar/2B.GPM.DPRGMI.CORRA2022.20200108-S082848-E100121.033302.V07A.HDF5','da118ff8a4ee76a1a37f96f9d95ad55c7a36a29f')\n",
    "  get('/gpmallversions/V07/2020/01/08/radar/2B.GPM.DPRGMI.CORRA2022.20200108-S174413-E191646.033308.V07A.HDF5','60681857a82c910b563ab6e40f443a15742acfe9')\n",
    "  get('/gpmallversions/V07/2020/01/09/radar/2B.GPM.DPRGMI.CORRA2022.20200109-S073715-E090948.033317.V07A.HDF5','662f6c73f3da0c1aabd0d2309258a6ae52b4b936')\n",
    "  get('/gpmallversions/V07/2020/01/11/radar/2B.GPM.DPRGMI.CORRA2022.20200111-S072635-E085907.033348.V07A.HDF5','4b35b18d519c404dfa0f8777fc3abd0a34bfc35a')\n",
    "  get('/gpmallversions/V07/2020/01/11/radar/2B.GPM.DPRGMI.CORRA2022.20200111-S164156-E181428.033354.V07A.HDF5','6299dcfc8339e0d7c46218fbe127d77390a5bb7f')\n",
    "  get('/gpmallversions/V07/2020/01/13/radar/2B.GPM.DPRGMI.CORRA2022.20200113-S163113-E180346.033385.V07A.HDF5','df78da2ac67aadf33e5125637a9da31dcb54cde4')\n",
    "  get('/gpmallversions/V07/2020/01/14/radar/2B.GPM.DPRGMI.CORRA2022.20200114-S062415-E075647.033394.V07A.HDF5','a75254c0c7fa76eb8814867c254bfe81b22e8ea4')\n",
    "  get('/gpmallversions/V07/2020/01/14/radar/2B.GPM.DPRGMI.CORRA2022.20200114-S153935-E171207.033400.V07A.HDF5','4ee5b4629723627b7d96e8f5a7b9732304399872')\n",
    "  get('/gpmallversions/V07/2020/01/16/radar/2B.GPM.DPRGMI.CORRA2022.20200116-S061330-E074603.033425.V07A.HDF5','401a46f5be0e97c1b16018a1bf8277bb1df26286')\n",
    "  get('/gpmallversions/V07/2020/01/16/radar/2B.GPM.DPRGMI.CORRA2022.20200116-S152851-E170123.033431.V07A.HDF5','afab3829113ee22f54a8106a60fe379cbce08181')\n",
    "  get('/gpmallversions/V07/2020/01/17/radar/2B.GPM.DPRGMI.CORRA2022.20200117-S052151-E065423.033440.V07A.HDF5','0e7e863bd1b7112acf4634aa19bddac81e6f908d')\n",
    "  get('/gpmallversions/V07/2020/01/19/radar/2B.GPM.DPRGMI.CORRA2022.20200119-S051105-E064338.033471.V07A.HDF5','42f21f60df38492d2f6f47c5fc8cffa827ea61f9')\n",
    "  get('/gpmallversions/V07/2020/01/19/radar/2B.GPM.DPRGMI.CORRA2022.20200119-S142626-E155857.033477.V07A.HDF5','6cdca9ac6e6cf80125e3564e43c997f576385cc0')\n",
    "  get('/gpmallversions/V07/2020/01/20/radar/2B.GPM.DPRGMI.CORRA2022.20200120-S041925-E055158.033486.V07A.HDF5','d7990d63a09eca4f19aeba27f39d2a61252bd885')\n",
    "  get('/gpmallversions/V07/2020/01/21/radar/2B.GPM.DPRGMI.CORRA2022.20200121-S141538-E154810.033508.V07A.HDF5','298544cc10c461d6a454b5b4e3f4f01c25f74927')\n",
    "  get('/gpmallversions/V07/2020/01/22/radar/2B.GPM.DPRGMI.CORRA2022.20200122-S040838-E054110.033517.V07A.HDF5','2df390ef68ac783afbf0c566b6188639bfd8b53c')\n",
    "  get('/gpmallversions/V07/2020/01/22/radar/2B.GPM.DPRGMI.CORRA2022.20200122-S132358-E145630.033523.V07A.HDF5','44d26bc953f3e87c9c5d48e56f7a59431f864cbe')\n",
    "  get('/gpmallversions/V07/2020/01/24/radar/2B.GPM.DPRGMI.CORRA2022.20200124-S131309-E144541.033554.V07A.HDF5','08c5e1417902e38e4a3f2d578ebd0ea9746d92db')\n",
    "  get('/gpmallversions/V07/2020/01/25/radar/2B.GPM.DPRGMI.CORRA2022.20200125-S030608-E043840.033563.V07A.HDF5','2431270b86ae74e1cce6bee5b7a829b9de3550c3')\n",
    "  get('/gpmallversions/V07/2020/01/25/radar/2B.GPM.DPRGMI.CORRA2022.20200125-S122128-E135400.033569.V07A.HDF5','f607d1792a78cf1a149e646207810511c2cb6d75')\n",
    "  get('/gpmallversions/V07/2020/01/27/radar/2B.GPM.DPRGMI.CORRA2022.20200127-S025518-E042750.033594.V07A.HDF5','ae0e9f8088136e92cfa3be988e7d034d4c621f27')\n",
    "  get('/gpmallversions/V07/2020/01/27/radar/2B.GPM.DPRGMI.CORRA2022.20200127-S121037-E134310.033600.V07A.HDF5','0c873112819111a3b5f30f6c2b1aa45cb7c5ca15')\n",
    "  get('/gpmallversions/V07/2020/01/28/radar/2B.GPM.DPRGMI.CORRA2022.20200128-S020336-E033609.033609.V07A.HDF5','7cf6b4c4584efae9833f498f67dbd1b5d776ee1d')\n",
    "  get('/gpmallversions/V07/2020/01/29/radar/2B.GPM.DPRGMI.CORRA2022.20200129-S115947-E133219.033631.V07A.HDF5','2927ffe6dd5b8e674d1aa85a6e40d418a42e3630')\n",
    "  get('/gpmallversions/V07/2020/01/30/radar/2B.GPM.DPRGMI.CORRA2022.20200130-S015245-E032517.033640.V07A.HDF5','3387b18dda43cca6cfed430c0f62ed7991b0b7bf')\n",
    "  get('/gpmallversions/V07/2020/01/30/radar/2B.GPM.DPRGMI.CORRA2022.20200130-S110804-E124036.033646.V07A.HDF5','95391ca4c4756a9ba8bc4b37ad851e81692ff2c5')\n",
    "\n",
    "  # Transfer complete; close connection\n",
    "\n",
    "  if ftpConnection:\n",
    "    ftpConnection.quit()\n",
    "  print ('Number of files downloaded: '+str(downloadCount))\n",
    "  if (skipCount>0):\n",
    "    print ('Number of files already downloaded: '+str(skipCount))\n",
    "\n",
    "  sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  if sys.version_info[0]<3:\n",
    "    raise Exception('Must use Python 3')\n",
    "  if (len(sys.argv)>1):\n",
    "    if (sys.argv[1].find('http')!=-1):\n",
    "      forceHttps=True\n",
    "    else:\n",
    "      usage()\n",
    "      sys.exit(1)\n",
    "  getPpsFiles()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudseeding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
